# C++

## 编译

### 编译流程

预处理 编译，汇编，连接

预处理就是宏展开，头文件完全拷贝进去

汇编完就已经是目标文件了，如果一个编译单元完全不依赖外部的函数或者全局变量，那么就这个目标文件就

### 动态和静态链接

关键字：重定位，重定位，符号表

------

静态链接：

静态链接发生在编译时，动态链接发生在加载时

链接很重要的一点就是重定位

> **链接（Linking）是过程，符号表（Symbol Table）是数据依据，重定位（Relocation）是最终手段**

编译是基于一个编译单元进行的，一个编译单元一次编译行为产出一个目标文件.obj，这时候，如果一个函数是在另一个编译单元定义的，就只能暂时做个记号，这个记号就存在符号表里

| **符号名** | **类型** | **状态**         | **偏移量 (Offset)**         |
| ---------- | -------- | ---------------- | --------------------------- |
| `main`     | 函数     | **已定义**       | `0x0000` (在当前文件的开头) |
| `count`    | 变量     | **已定义**       | `0x0004`                    |
| `printf`   | 函数     | **未定义 (UND)** | `?` (等链接器处理)          |

重定位的过程：

1. **合并：** 链接器把所有输入文件的代码段 (`.text`) 和数据段 (`.data`) 合并。
2. **计算地址：** 链接器决定最终的内存布局。假设 `printf` 最终被安放在 `0x0804`。
3. **打补丁 (Patching)：** 链接器根据 **重定位表** 的指引，找到那个暂时填了 `0x0000` 的坑，把它修改为真实的地址 `0x0804`。

------

动态链接：

因为动态链接库被不同的程序加载的位置可能不同，因此动态链接库在编译时生成的指令不能包含相对地址，也就是地址无关代码 PIC

两个关键数据结构：GOT 和 PLT 的出现，是为了让代码段（Code Segment，只读、可共享）**保持不变，而将变化的地址放在** 数据段（Data Segment，可读写、每个进程私有）

(1) GOT (Global Offset Table) —— 全局偏移表

- **本质：** 一个数组，存放着绝对虚拟地址。
- **位置：** 数据段（`.data`）。
- **作用：** 代码想要访问外部变量或函数时，不直接访问，而是去查 GOT。GOT 里存的才是真正的地址。
- **关键点：**
  - 1.  因为 GOT 在数据段，每个进程都有自己的一份 GOT。加载器只需要修改 GOT 里的值，而不需要修改代码段的指令。
  - 2. **GOT 是相对于“使用库的程序”（调用方）来说的。** 更准确地说：**每一个编译单元（Executable 或 Shared Library），只要它引用了外部符号，它就必须维护一份属于自己的 GOT。**
    3. 

(2) PLT (Procedure Linkage Table) —— 过程链接表

- **本质：** 一小段跳板代码（Trampoline）。
- **位置：** 代码段（`.text`）。
- **作用：** 它是外部函数的“代理人”。当你的程序调用 `printf` 时，实际上是调用了 `printf@plt`。

现代动态链接器非常懒。程序启动时，它不会把成千上万个函数的地址都解析出来（那太慢了）。它采用了 **延迟绑定** 策略：**只有当你第一次调用某个函数时，链接器才去解析它的地址。**

> 让我们看看当你调用 `printf` 时，底层发生了什么：
>
> #### 阶段一：编译完成时
>
> - **代码中：** 调用指令指向 `printf@plt`。
> - **GOT 中：** `printf` 对应的条目填的不是真实地址，而是 **指回 PLT 的下一条指令**（这就像写着“我不知道，你问上面吧”）。
>
> #### 阶段二：第一次调用 `printf`
>
> 1. **代码跳转：** `call printf@plt`。
> 2. **PLT 跳转：** PLT 第一条指令是 `jmp *GOT[printf]`。
> 3. **回马枪：** 因为是第一次，GOT 里存的是 PLT 的下一行代码。所以指令并没有跳去真正的 printf，而是跳回了 PLT 的下一行。
> 4. **召唤链接器：** PLT 接着做两件事：
>    - 把 `printf` 的 ID 压栈。
>    - 调用动态链接器（Runtime Linker, `ld-linux.so`）的解析函数 `_dl_runtime_resolve`。
> 5. **解析地址：** 动态链接器去查找 `libc.so` 的符号表，找到了 `printf` 的真实内存地址（比如 `0xDEADBEEF`）。
> 6. **填表：** 链接器把这个真实地址 `0xDEADBEEF` 填入 **GOT** 中。
> 7. **执行：** 链接器跳转到 `0xDEADBEEF` 执行真正的 `printf`。
>
> #### 阶段三：第二次调用 `printf`
>
> 1. **代码跳转：** `call printf@plt`。
>
> 2. **PLT 跳转：** `jmp *GOT[printf]`。
>
> 3. **直达目标：** 这一次，GOT 里已经是真实的 `0xDEADBEEF` 了。程序直接飞到 `printf` 函数体执行。
>
>    **Code:** `call PLT[printf]` ↓ **PLT [printf]:** `jmp *GOT[printf]` │ ├─── **(第一次)** ──→ 查 GOT 发现是“自己下一行” → `push ID` → `Call Linker` → **修改 GOT** → `Run Function`│└─── **(第二次)** ──→ 查 GOT 发现是“真实地址” ────→ `Run Function`

------

注意：

1. **动态链接的 GOT 表项：** 存的是 **绝对地址**。

   **静态链接的指令码：** 存的大多是 **相对偏移**。

   为什么呢：因为静态链接的代码段是连续的，但是动态链接的代码段是不连续的

2. 动态链接的时候，是如何找到函数的绝对虚拟地址的呢？

   链接器维护了一个非常重要的数据结构，叫 **`link_map`**。这是一个 **双向链表**，记录了当前进程加载的所有模块（包括主程序自己和所有依赖库）。

   链表大概长这样： `[Game.exe] <-> [libstdc++.so] <-> [libc.so] <-> [kernel32.dll] ...`

   每个节点里都记录了关键信息：

   - **名字**：比如 `libc.so`
   - **基址 (Base Address)**：比如 `0x7ffff7a00000` (这是操作系统加载时随机分配的)
   - **符号表位置**：指向该库内部 `.dynsym` 的指针。

   > 1. 链接器计算 "printf" 的哈希值。
   > 2. 在 `libc.so` 的哈希表里快速定位。
   > 3. 定位到符号表中的具体条目。
   > 4. 读取该条目，发现：**`printf` 在本文件内部的偏移量 (Offset) 是 `0x500`。**
   >
   > 现在所有拼图都齐了：
   >
   > 1. **基址 (Base)：** 在第二步遍历 `link_map` 时，链接器知道 `libc.so` 被加载到了 `0x7ffff7a00000`。
   > 2. **偏移 (Offset)：** 在第三步查符号表时，知道 `printf` 在库内的位置是 `0x500`。

   也就是说，链接器知道每一个动态链接库的基址，也可以通过动态链接库的符号表知道一个具体函数的 Offset，用基址+Offset 就可以得到绝对虚拟地址

3. 主程序知道连接方式，也分知晓和不知晓：

   > 在构建程序的过程中，**编译器（Compiler）** 和 **链接器（Linker）** 确实会根据“目标函数是静态库里的还是动态库里的”，生成完全不同的指令代码。
   >
   > 为了讲清楚这个“区别对待”的过程，我们需要把视角分为 **Windows (MSVC)** 和 **Linux (GCC/Clang)** 两种流派，因为它们的处理策略完全不同。
   >
   > ------
   >
   > ### 1. Windows 的做法：显式告知 (Explicit)
   >
   > 在 Windows 开发中（C++/DX12），你应该经常见到 `__declspec(dllimport)` 这个宏。这玩意儿就是用来 **提前告诉编译器**：“嘿，这个函数是动态链接的！”
   >
   > #### 场景 A：编译器不知道是动态链接 (没有写 `dllimport`)
   >
   > 如果你只写了 void foo();，编译器默认以为它是静态链接（或者同一个模块里的函数）。
   >
   > 编译器生成的指令是普通的相对跳转：
   >
   > ```Code snippet
   > call foo  ; 编译器以为 foo 就在附近
   > ```
   >
   > 到了链接阶段，链接器发现 foo 其实在 DLL 里。怎么办？编译器生成的指令已经是 call 相对地址 了，改不了了。
   >
   > 补救措施： 链接器被迫在你的代码里偷偷插入一段小代码（Thunk/Stub），看起来像这样：
   >
   > ```Code snippet
   > ; 这一段是链接器自动生成的桩代码
   > foo_stub:
   >     jmp *__imp_foo  ; 跳去查导入表 (IAT)
   > ```
   >
   > 然后把原本的 call foo 修改为 call foo_stub。
   >
   > 代价： 多了一次跳转（Call -> Stub -> DLL）。
   >
   > #### 场景 B：编译器知道是动态链接 (写了 `dllimport`)
   >
   > 如果你写了 __declspec(dllimport) void foo();。
   >
   > 编译器一看：“哦，这是别人的函数。”
   >
   > 它会直接生成最高效的间接调用指令，跳过中间商：
   >
   > ```Code snippet
   > call *__imp_foo  ; 直接去读导入表里的地址并跳转
   > ```
   >
   > **结果：** 省略了中间那个 Stub，性能更高。
   >
   > ------
   >
   > ### 2. Linux 的做法：统一代理 (Implicit)
   >
   > Linux (ELF) 的哲学不一样。它默认假设 **你不知道** 这个函数在哪（可能是静态，可能是动态）。
   >
   > #### 编译器策略：全都推给 PLT
   >
   > GCC 在编译 main.c 时，看到 printf，它根本不管 printf 是静态还是动态。
   >
   > 它一律生成指向 PLT 的代码：
   >
   > ```Code snippet
   > call printf@plt
   > ```
   >
   > #### 链接器策略：最后裁决
   >
   > 到了链接阶段 (`ld`)，链接器看着你给它的库文件，决定怎么填这个坑：
   >
   > 1. **如果你给的是静态库 (`libc.a`)：**
   >    - 链接器把 `printf` 的二进制代码 **抄** 到你的可执行文件里。
   >    - 链接器会把那行 `call printf@plt` **修改**（重写）为直接调用 `call printf_body`（不再走 PLT/GOT 那一套，或者虽然保留符号，但指向本地代码）。
   >    - *注：现代链接器优化可能会直接消除 PLT 引用。*
   > 2. **如果你给的是动态库 (`libc.so`)：**
   >    - 链接器生成真正的 **PLT 表** 和 **GOT 表**。
   >    - 保留 `call printf@plt` 不变。
   >    - 建立对 `libc.so` 的动态依赖信息。
   >
   > ------
   >
   > ### 3. 核心差异总结：代码长什么样？
   >
   > 主程序（调用者）根据“知不知道是动态链接”，最终生成的汇编指令会有本质区别。
   >
   > 我们用伪代码对比一下 **调用 `foo()`** 的三种最终形态：
   >
   > | **情景**                               | **主程序生成的指令**   | **机制**         | **备注**                                                |
   > | -------------------------------------- | ---------------------- | ---------------- | ------------------------------------------------------- |
   > | **静态链接**                           | `call 0x1000`          | **直接相对跳转** | 最快。地址是写死的相对偏移。                            |
   > | **动态链接 (Windows `dllimport`)**     | `call *[0x5000]`       | **间接内存跳转** | 也是最快（针对动态）。直接去读 IAT 表里的绝对地址跳走。 |
   > | **动态链接 (Linux 默认 / Win 无声明)** | `call 0x2000` (去 PLT) | **跳板模式**     | 稍慢。先跳到 PLT (0x2000)，PLT 再查表跳走。             |
   >
   > ### 你的结论
   >
   > **是的，你的理解完全正确。**
   >
   > - **编译期知晓：** 如果通过关键字（如 `dllimport`）让编译器提前知道了，编译器就能生成 **直接查表** 的代码（`call *ADDR`），省去中间跳转。
   > - **链接期知晓：** 即使编译器不知道，链接器在最后时刻看到了库文件（`.a` vs `.so`），它会决定是 **拷贝代码**（静态）还是 **生成 PLT/GOT 条目**（动态）。
   >
   > 这就是为什么在 C/C++ 头文件中，经常看到这种宏定义：
   >
   > ```C++
   > #ifdef MY_LIB_EXPORT
   >   #define API __declspec(dllexport) // 编译 DLL 时：我是导出者
   > #else
   >   #define API __declspec(dllimport) // 编译主程序时：我是导入者（编译器：懂了，我给你生成优化的间接调用代码）
   > #endif
   > 
   > API void MyFunction();
   > ```
   >
   > 这个宏的存在，就是为了让主程序在编译时 **“知道”** 这是一个动态链接函数，从而选择最优的链接方式。

## 基础语法

### 四种 cast 和 bit_cast

### 类型转换（CStyle 和 C++Style）





------

explict 和 implict



### 基本类型大小

### 整数存储方式，Float 存储方式

### C++调用栈

[调用栈]: ..\面经\C++\C++栈调用.md

### Static 关键字，Extern 关键字

### C++链接性



### 内存四区

### 字符串字面量存储在哪里？



## 类和对象

### 异常处理

https://zhuanlan.zhihu.com/p/65454580

```c++
void f1() throw(int){           //函数f1会抛出一个整型的异常代码
  cout<<"f1 starts"<<endl;
  int i;                       //这个变量会在栈展开的过程中被释放资源
  throw 100;                   //抛出异常，程序开始在栈中搜索对应的异常处理器，即开始栈展开
  cout<<"f1 ends"<<endl;       //这行代码不会被执行
}

void f2 throw(int){            //函数f2调用了f1，所以抛出异常的类型也是整型
  cout<<"f2 starts"<<endl;
  int j;                      //这个变量也会在栈展开的过程中被释放资源
  f1();                       //f1没有搜索到对应的异常处理，因此返回到f2搜索
  cout<<"f2 ends"<<endl;      //这行代码也不会被执行
}

void f3(){
  cout<<"f3 starts"<<endl;
  try{                        //函数f3在try里调用f2，并可能会catch一个整型的异常
    f2();
  }catch(int i){              //f2也没有找到异常处理，最后返回了f3并找到了异常处理
    cout<<"exception "<<i<<endl;
  }
  cout<<"f3 ends"<<endl;
}

int main(){
  f3();
  return 0;
}
```

在 C++里，当有异常被抛出，**调用栈**(call stack)，即栈中用来储存函数调用信息的部分，会被按次序搜索，直到找到对应类型的处理程序(exception handler)。而这里的搜索顺序就是 f1-> f2-> f3。f1 没有对应类型的 catch 块，因此跳到了 f2，但 f2 也没有对应类型的 catch 块，因此跳到 f3 才能处理掉这个异常。

以上这个寻找异常相应类型处理器的过程就叫做 **栈展开**。同时在这一过程中，当从 f1 返回到 f2 时，f1 里局部变量的资源会被清空，即调用了对象的析构函数。同样，在从 f2 返回到 f3 时，f2 里局部变量也会被调用析构函数并清空资源。

之前的时候是基于EBP实现的，现代主要基于静态表。

基于表的栈展开在**时间上是非常昂贵的**

### 构造函数和析构函数能否抛出异常/noexcept

构造函数可以抛出异常

但是有个问题，如果一个构造函数构造到了一半，同时它申请内存成功了，这时候抛出异常，就会导致内存泄漏。

例如：

```c++
class Dangerous {
    int* ptr;
public:
    Dangerous() {
        ptr = new int[100]; // 1. 资源分配成功
        
        // ... 中间做了一些逻辑 ...
        
        if (true) { // 2. 突然发现参数不对，抛出异常
            throw std::runtime_error("初始化失败");
        }
    }

    ~Dangerous() {
        delete[] ptr; // 3. ！！！这句话永远不会执行！！！
        std::cout << "析构函数执行" << std::endl;
    }
};

int main() {
    try {
        Dangerous d; 
    } catch(...) {
        // 捕获了异常，但 new int[100]  leaking 了，永远找不回来了
    }
}
```

但是，C++保证的是，在抛出异常之前，所有已经成功构造成功的成员，会触发它的析构函数（如下，不允许抛出异常）。这就是 RAII 的好处了

```c++
#include <vector>
#include <memory>
class Safe {
    std::unique_ptr<int[]> ptr; // 使用智能指针
    std::vector<int> buffer;    // 使用容器
public:
    Safe() : ptr(new int[100]) { // 1. 智能指针接管内存
        
        buffer.resize(500); // 2. vector 分配内存
        
        // 3. 这里抛出异常
        throw std::runtime_error("安全报错");
    }
    // 根本不需要写析构函数，或者析构函数不执行也没关系
};

// 发生异常时的剧本：
// 1. 构造函数抛出异常。
// 2. 运行时发现 Safe 对象构造失败。
// 3. 运行时开始逆序清理成员：
//    - 调用 buffer 的析构函数 -> 释放 vector 内存。
//    - 调用 ptr 的析构函数 -> delete[] 那个 int 数组。
// 4. 内存完全回收，没有任何泄漏。
```

------

https://zhuanlan.zhihu.com/p/65454580

C++11 之后，**所有析构函数默认都是 `noexcept(true)` 的**，析构函数是绝对不能抛出异常的，如果再析构函数里抛出异常，程序会直接 crash。

析构函数不跑出异常，最核心的考量是：**防止“双重异常”（Double Exception）**

C++异常处理依靠的是栈展开

想象一下这个场景：你的程序出了问题，抛出了一个异常（Exception A）。

1. **异常 A 抛出**：程序中断当前逻辑。
2. **栈展开开始**：C++ 运行时（Runtime）开始寻找 `catch` 块。在跳到 `catch` 之前，它必须先清理案发现场。
3. **清理现场**：这意味着当前栈帧里的所有局部变量必须被销毁，也就是 **调用它们的析构函数**。
4. **二次爆炸**：就在这个清理过程中，万一某个对象的析构函数里又抛出了一个异常（Exception B）……（好好品味这里，这里的某个对象的析构函数，居然抛出了异常，这才是不允许抛出异常的核心原因）

**这时候 C++ 运行时就崩溃了。** 它手里正捏着“异常 A”还没处理完（还在找 catch 呢），突然你又塞给它一个“异常 B”。它不知道该先处理哪个，也不知道该往哪里跳。

```c++
#include <iostream>
#include <exception>

class BadDestructor {
public:
    ~BadDestructor() { // C++11 默认为 noexcept，这里为了演示，假设它能抛
        // 如果这里抛出异常...
        throw std::runtime_error("我是捣乱的析构异常"); 
    }
};

void func() {
    BadDestructor bad;
    // 1. 这里抛出了第一个异常
    throw std::runtime_error("我是原始异常"); 
    
    // 2. 遇到异常，开始栈展开，准备销毁 bad 对象
    // 3. 调用 bad.~BadDestructor()
    // 4. 析构函数里又抛出一个异常 -> BOOM! 程序直接 terminate
}

int main() {
    try {
        func();
    } catch (...) {
        std::cout << "你永远看不到这句话" << std::endl;
    }
}
```



### 普通函数指针，函数对象以及成员函数指针



### 内存对齐以及计算方式，为什么要有内存对齐

如果不对齐：

> 假设你把 `int` 放在了地址 `0x01-0x04`。 CPU 为了读这个整数，需要做“极其痛苦”的操作：
>
> 1. 第一次读取：读 `0x00-0x03`，把后 3 个字节拿出来。
> 2. 第二次读取：读 `0x04-0x07`，把第 1 个字节拿出来。
> 3. **位运算拼接：** 在寄存器里把这两部分拼凑成一个完整的 `int`。

1. CPU 读取内存的粒度通常是 **字 (Word)** 或 **双字**。未对齐的访问可能会导致指令周期加倍。
2. 对齐的读写通常是原子的（Atomic）。未对齐的读写因为涉及两次内存访问，中间可能被其他线程打断。

对齐规则：成员对齐和整体对齐

1. 成员对齐是说：某个成员的偏移量必须是该成员大小的整数倍，比如一个 int，它的地址就必须是从 4 的整数倍开始，一个 short 必须从 2 的整数倍
2. 整体对齐：结构体的大小必须是 **最大成员** 大小的整数倍（这是为了让在数组存储的时候，下一个元素也能对齐）
3. 注意：结构体的对齐值 = **它内部最大成员的对齐值**

```c++
struct Inner {
    char x; // 1
    // pad 3 (为了 int 对齐)
    int y;  // 4
}; 
// sizeof(Inner) = 8
// alignof(Inner) = 4 (因为里面最大的成员是 int) <-- 关键点！
```



例 1：

```c++
struct Test {
    char a;   // 1字节
    // --- 编译器插入 3 字节 Padding ---
    int b;    // 4字节 (必须从 4 的倍数开始)
    short c;  // 2字节
    // --- 编译器插入 2 字节 Padding ---
};
```

> 64 位系统 (x64)
>
> `bool` / `char`: 1 字节
>
> `short`: 2 字节
>
> `int` / `float`: 4 字节
>
> `double` / `long long` / `指针(void*)`: 8 字节
>
> ### 第一题：基础热身
>
> 这是最经典的“乱序”结构体，考察基础的填充规则。
>
> ```C++
> struct Question1 {
>     char a;
>     double b;
>     int c;
>     char d;
> };
> ```
>
> **问题：** `sizeof(Question1)` 是多少？							24
>
> ------
>
> ### 第二题：数组陷阱
>
> 数组的对齐规则是按整体算，还是按元素类型算？
>
> ```C++
> struct Question2 {
>     int a;
>     char b[9];  // 注意是大小为9的数组
>     short c;
>     double d;
> };
> ```
>
> **问题：** `sizeof(Question2)` 是多少？						24
>
> ------
>
> ### 第三题：嵌套结构体
>
> 当结构体里套着另一个结构体时，对齐规则怎么算？
>
> ```C++
> struct Inner {
>     char x;
>     int y;
> };
> 
> struct Question3 {
>     char a;
>     Inner b; 
>     char c;
> };
> ```
>
> **问题：** `sizeof(Question3)` 是多少？					16，结构体的对齐值是根据它内部最大的成员的对齐值，而不是整个系统字长
>
> ------
>
> ### 第四题：空间优化 (Reordering)
>
> 作为一名追求性能的游戏开发者，你应该知道如何通过重排成员来节省内存。
>
> ```C++
> // 原始结构体
> struct Question4_Raw {
>     char a;
>     double b;
>     bool c;
>     int d;
>     short e;
> };
> ```
>
> **问题：**
>
> 1. `sizeof(Question4_Raw)` 是多少？			32
>    1. 如果你可以随意改变成员定义的顺序，**最小** 能把它优化到多大？		16
>
> ------
>
> ### 第五题：魔法指令 (Pack vs Alignas)
>
> 考察你对强制对齐指令的理解。
>
> ```C++
> // 情况 A: 强制压缩
> #pragma pack(push, 1) // 告诉编译器：别管什么对齐规则了，挨着放！
> struct Question5_A {
>     char a;   // 1
>     int b;    // 4 (直接放在 offset 1，不管对齐)
>     double c; // 8 (直接放在 offset 5)
> };
> #pragma pack(pop)
> 
> // 情况 B: 强制对齐 (比如为了 SIMD)
> struct alignas(16) Question5_B {
>     char a; // 1
>             // 编译器为了内部的 int b (4字节对齐)，这里还是会补 3
>     int b;  // 4
>             // 目前数据只用到了 offset 0~7，共 8 字节。
> };
> ```
>
> **问题：** `sizeof(Question5_A)` 和 `sizeof(Question5_B)` 分别是多少？      13/16

DX12 的常量缓冲区 CBV 必须是 256 字节对齐的

------





### C++当中，一个空类也是有内存大小的，那么为什么要这样呢，以及这个大小中存储的是什么呢

C++ 的设计哲学规定，**“身份” (Identity) 是通过“地址” (Address) 来区分的**。

假设一个空类：

```c++
class Empty {};
```

那么我声明两个 Empty 对象：

```c++
int main() {
    Empty e1;
    Empty e2;

    // 如果 sizeof(Empty) == 0，那么 e1 和 e2 的地址会是什么？
    // 它们很可能会是同一个地址！
    if (&e1 == &e2) {
        // 这就出问题了！e1 和 e2 是两个不同的对象，
        // 但我们无法在内存中区分它们。
    }
}
```

如果要区分 e1 和 e2，就他们的地址就必须不同，地址不同就导致这俩必须要占用空间

因此，C++ 标准规定，**任何对象（Object）的大小至少为 1 字节**（即使它没有任何成员）。

**这个 1 字节里存储的是什么**

这个 1 字节是 **纯粹的“占位符” (Padding)**。

**空基类优化**

你可能会想：“如果我继承一个空类，我的类会变大 1 字节吗？”

**答案：通常不会！** 这就是“空基类优化” (Empty Base Optimization, EBO)。

虽然一个 **独立** 的空类对象必须占用 1 字节，但当一个空类 **作为基类** 时，编译器足够聪明，可以“压缩”掉这个字节。

```
class Empty {}; // sizeof(Empty) == 1

class Derived : public Empty { // 继承 Empty
    int data; // sizeof(int) == 4
};
```

**按理说：** `sizeof(Derived)` 应该是 `sizeof(Empty) + sizeof(int) = 1 + 4 = 5` 字节？

**实际上：** 编译器会执行 EBO。它会让 `Empty` 基类部分 **“寄宿”** 在 `Derived` 对象的内存中，和 `data` 成员共享同一个起始地址（或者说，让 `Empty` 部分占用 0 字节）。

### 默认构造函数什么时候会默认生成，三五原则



## 移动语义

### 移动语义需要 noexcept

这个问题来自我写的一个测试代码：
```c++
#include<iostream>
#include<vector>
using namespace std;
class A {
public:
	A() {
		cout << "Construct" << endl;
	}
	A(A&& other) {
		cout << "Move" << endl;
	}
	A(const A& other) {
		cout << "Copy" << endl;
	}
};

int main() {
	vector<A> vec;
	vec.reserve(4);
	vec.push_back(A());
	cout << endl;

	A a;
	vec.push_back(a);
	cout << endl;

	A b;
	vec.push_back(std::move(b));
	cout << endl;

	vec.emplace_back();

	//Construct
	//Move

	//Construct
	//Copy

	//Construct
	//Move

	//Construct

}
```

这里的输出其实有很多问题，为什么，我是用了移动语义，但是 b 和 emplaceback 还是这么多 copy，

问题在于，移动操作对于移动源头是破坏性的，因此，很多容器都要求，如果移动语义不是安全的，那么就不去移动，而是选择拷贝来替代

## 运行和优化

### 运行时 函数调用栈帧移动方式

[](..\面经\C++\C++栈调用.md )

### 返回值优化 RVO（C++17）

如果编译器发现，一个函数内的局部变量，最终是要给外面的，那么在函数运行时，这个会直接把外部接收的那个变量作为一个参数压栈，然后在内部赋值

```c++
std::string getStr() {
    std::string temp = "Hello World"; // 局部变量
    return temp;
}

std::string s = getStr();
```

优化后类似于：

```c++
std::string getStr(string* s) {
    *s= "Hello World"; // 局部变量
    return temp;
}

std::string s;
getStr(&s);
```

下面这些都会触发 ROV

```c++
std::vector<int> generateBigData() {
    std::vector<int> data;
    data.reserve(1000000);
    for(int i=0; i<1000000; i++) data.push_back(i);
    
    return data; // 触发 NRVO (Named RVO)
}

// 这里的 v 直接接管了 data 在函数内部申请的那块堆内存
// 栈上的 vector header 也是直接构造在 v 的位置
std::vector<int> v = generateBigData();

class Logger {
public:
    Logger() { printf("构造\n"); }
    ~Logger() { printf("析构\n"); }
    // 假设禁用了拷贝和移动（为了演示）
    Logger(const Logger&) = delete;
    Logger(Logger&&) = delete;
};

Logger createLogger() {
    return Logger(); // RVO 直接在外部变量地址构造
}

int main() {
    Logger log = createLogger();
    // 输出：
    // 构造
    // (没有拷贝，没有移动)
    // 析构
}
```





### Implicit Move (隐式移动) 

如果 RVO 无法实施，如果返回值是函数内的局部对象，那么编译器必须将其自动视为 RValue

也因此，如果对象实现了移动语义，它会触发移动语义的操作符或者构造函数。

## 内存管理

### Malloc 原理，内存池管理



### Malloc/free，new/delete 的区别



### delete 和 delete [] 的区别，以及为什么会有这种区别



### 全局的:: new 和 operator new

`new` 一个类（new Expression）

当你写 `MyClass* p = new MyClass();` 时，你使用的是 **new 表达式**。 这是一个 **不可重载** 的内置运算符，它是一套 **固定的流程**，编译器会把它翻译成以下三步动作：

1. **算大小：** 计算 `MyClass` 需要多少字节。
2. **申请内存 (Allocate)：** 调用 **`operator new`** 函数来申请那块原始内存。
   - *注意：这里就是两者发生关系的地方。*
3. **构造对象 (Construct)：** 在这块申请好的内存上，调用 `MyClass` 的构造函数（其实就是 Placement New）。

全局的 `::operator new`

当你写 `void* p = ::operator new(100);` 时，你调用的是一个 **普通的函数**。

- 它的地位：它和 `malloc` 几乎是一样的。
- 它的职责：**只管给内存，不管对象。** 它不知道什么是类，什么是构造函数，它只接收一个 `size_t` 参数，返回一个 `void*` 指针。

大部分的实现里，:: new 最后还是用的是 malloc

无论是全局的 new 还是 operator new，都要用 delete

但是区别在于，全局的 new 最后对应的是全局的:: operator delete（底层基本还是 free），operator new 最后释放的是 operator delete，但是无论如何都要对应上

下面这样是不对的

```cpp
// 1. 只申请了内存，没有调用构造函数！
void* raw_mem = ::operator new(sizeof(MyClass)); 

// 强转一下，为了能编译通过
MyClass* ptr = static_cast<MyClass*>(raw_mem);

// 2. 错误！试图用 delete 释放
delete ptr;
```

这样就对了

```cpp
// 1. 只申请了内存，没有调用构造函数！
void* raw_mem = ::operator new(sizeof(MyClass)); 

MyClass* ptr = static_cast<MyClass*>(raw_mem);
MyClass* ptr = new (raw_mem) MyClass();//构造

ptr->~MyClass();
::operator delete(ptr);
```

上面这个就是 C++ 标准库容器（如 `std::vector`）和 `std::make_shared` 底层真正的运作方式

**`::operator new` 就是 `malloc` 的一层“精装修”外壳。** **`::operator delete` 就是 `free` 的一层简单封装。**
$$
\text{:: operator new} = \text{malloc} + \text{错误处理机制 (Exception + Handler)}
$$




## 数据结构与算法以及 STL

### 红黑树底层，延伸到 STL 的 Map 和哈希表

### std:: sort 是如何优化的

### vector 是如何扩容的



### `emplace_back` 和 `push_back`

`push_back` 接受的是一个 **已经存在的对象**（或者它能隐式转换成的对象）

正常来说呢，push_back 需要先构造一个对象，然后再拷贝或者移动获取







### deque 是如何管理空间，如何实现 O1 的插入队首和队尾的，以及作为 Adapte 的 Stack 和 Queue

deque



### C++和 C 对于字符串的优化实现，以及 C++ stl：string 的实现

0. 古老的已经被废弃的技术；COW，写时复制

当拷贝一个字符串 `s2 = s1` 时，不立即复制数据，而是让 `s2` 指向 `s1` 的数据，并将引用计数 +1。只有当有人试图 **修改** 其中一个字符串时，才真正进行内存复制。

**为什么被废弃？ (C++11)**

​	a. **多线程开销大：** 为了线程安全，引用计数必须是 **原子操作**（Atomic）。原子操作在多核 CPU 上的开销远大于直接复制短字符串的开销。

​	b. **标准限制：** C++11 标准规定 `operator[]` 和 `iterator` 不能失效（除非发生重新分配），这使得 COW 的实现变得极其复杂且难以维护。

------



1. 短字符串优化

程序中大量的字符串其实很短（比如文件名、单词、人名，通常小于 15 个字符）。如果每个短字符串都要去堆（Heap）上 `malloc` 一次内存，开销巨大且容易造成内存碎片。

`std::string` 对象本身在栈上占据一定大小（通常是 24 或 32 字节，取决于指针大小）。

- **当字符串很长时：** 对象内部存储的是：`[指针 ptr] + [大小 size] + [容量 capacity]`，数据存在 **堆** 上。
- **当字符串很短时：** 直接复用这块空间，利用 `union` 将指针和容量的内存当做 **字符数组** 使用，数据存在 **栈**（或对象所在的内存）上。

------



2. 移动语义

在 C++11 之前，函数返回 `std::string` 会导致深拷贝。

- **优化机制：** 引入右值引用（Rvalue Reference, `&&`）后，`std::string` 实现了移动构造函数和移动赋值操作符。

  - 它不复制字符数据。
  - 它直接“偷走”源对象的内部指针（ptr），并将源对象置为空。

  ```C++
  std::string createBigString() {
      std::string s(1000, 'a');
      return s; // C++11 之前：深拷贝；C++11 及之后：移动（几乎零成本）
  }
  
  std::string a = createBigString(); // 仅仅交换了几个指针
  ```

------



3. std:: string_view 零拷贝切片(C++17)

有点类似于 C#的那个数组切片，仅仅传递一个只读的视图

```c++
void process(std::string_view sv) { 
    // 既能接 std::string，也能接 "literals"，且无任何内存分配
}
//std::string_view 是一个极轻量级的对象，只有两个成员：
//	const char* ptr (指向数据的开始)
//	size_t size (长度)
//主要节省在字面量，比如一个"Hello"可以直接传给string_view的ptr
```

------



4. 手动优化技巧：`reserve()` 与 `shrink_to_fit()`

虽然标准库做了很多，但开发者手动的优化依然关键：

- **`reserve(n)`：预分配内存** 如果你知道字符串大概会多长，**务必** 先调用 `reserve`。

  - *原因：* 字符串增长时，通常会按倍数扩容（如 1.5 倍 或 2 倍）。如果不 `reserve`，在 append 过程中会发生多次 `malloc` -> `memcpy` -> `free`。

  ```C++
  std::string s;
  s.reserve(1024); // 一次分配搞定
  for(int i=0; i<100; ++i) s += "data"; // 此时没有额外的内存分配
  ```

- **`shrink_to_fit()` (C++11)：释放多余内存** 如果一个字符串曾经很大，现在变小了，`capacity` 依然很大。调用此函数请求释放多余的堆内存（虽然是非强制的，但通常有效）。





### 迭代器分类

### hash 冲突如何解决

### 跳表

### 堆排序和优先队列



### 各种排序算法





## 智能指针



### Unique_ptr

独占资源，不允许所有的拷贝语义，只允许移动语义

------



### Maked_Shared

先说用法：

```cpp
var sp = make_shared<T>(args)
```

make_shared 是基于一次内存分配，然后用 placement new 构造对象。对象的参数用的完美转发，实现的就是一次内存申请就构造

makeshared 的意义有二：1. 内存紧凑，缓存友好。控制块和用户的指针位置在一起 2. 一次内存分配，更安全

------



### Shared_ptr 线程安全吗

1. 引用计数线程安全
2. 通过引用计数访问修改 T 资源本身的线程安全不保证，需要自己加锁
3. 多线程操作不同的 SharedPtr 是安全的
4. `shared_ptr` 对象本身是线程不安全的

> **场景**：有一个 **全局** 变量 `std::shared_ptr<T> global_sp`。
>
> - 线程 A 执行：`global_sp = std::make_shared<T>(new_obj);` （写操作）
> - 线程 B 执行：`auto local_sp = global_sp;` （读操作）
>
> **赋值操作不是原子的！** 当执行 `global_sp = new_sp` 时，底层其实发生了两步操作（简化版）：
>
> 1. `global_sp._ptr = new_sp._ptr;`
> 2. `global_sp._cb = new_sp._cb;`



### 实现 Shared_ptr

placement_new 语法：

```cpp
new (address) Type(arguments...);
```



```c++
#include <iostream>
#include <atomic>
#include <new>
#include <utility> // for std::forward
#include <cstdlib> // for malloc/free

// ControlBlock 不需要模板 T，除非你需要自定义 Deleter
struct ControlBlock {
    std::atomic<int> _strong_refs;
    std::atomic<int> _weak_refs;

    ControlBlock() : _strong_refs(1), _weak_refs(1) {}
};

template<class T>
class MySharedPtr {
private:
    T* _data_ptr;
    ControlBlock* _cb;
    void* _cb_pos;      // 记录实际分配的那块内存首地址
    bool _is_continuous; // 【修正】：标记内存是否连续（make_shared 模式）

public:
    // 【修正】：Separate Allocation 通常接收 T*
    explicit MySharedPtr(T* data) : _data_ptr(data), _is_continuous(false) {
        if (data) {
            _cb = new ControlBlock();
            _cb_pos = _cb; // 在这种模式下，cb_pos 指向 ControlBlock
        }
        else {
            _cb = nullptr;
            _cb_pos = nullptr;
        }
    }

    // 给 Make_Shared 用的私有构造函数
    MySharedPtr(T* data, ControlBlock* cb, void* cb_pos, bool continuous)
        : _data_ptr(data), _cb(cb), _cb_pos(cb_pos), _is_continuous(continuous)
    {
    }

    // 移动构造
    MySharedPtr(MySharedPtr&& other) noexcept {
        _data_ptr = other._data_ptr;
        _cb = other._cb;
        _cb_pos = other._cb_pos;
        _is_continuous = other._is_continuous;

        other._data_ptr = nullptr;
        other._cb = nullptr;
        other._cb_pos = nullptr;
    }

    // 拷贝构造
    MySharedPtr(const MySharedPtr& other) {
        _data_ptr = other._data_ptr;
        _cb = other._cb;
        _cb_pos = other._cb_pos;
        _is_continuous = other._is_continuous;
        if (_cb) {
            _cb->_strong_refs.fetch_add(1, std::memory_order_relaxed);
        }
    }

    ~MySharedPtr() {
        if (!_cb) return;

        // 1. 强引用归零 -> 销毁对象
        if (_cb->_strong_refs.fetch_sub(1, std::memory_order_acq_rel) == 1) {

            if (_is_continuous) {
                //如果是 make_shared，只能手动析构，不能 delete 指针（因为内存不是它单独申请的）
                _data_ptr->~T();
            }
            else {
                // 如果是 new T 传进来的，delete 会同时调用析构 + 释放内存
                delete _data_ptr;
            }

            // 2. 弱引用归零 -> 释放控制块内存
            if (_cb->_weak_refs.fetch_sub(1, std::memory_order_acq_rel) == 1) {
                if (_is_continuous) {
                    // make_shared 模式：释放整个大块内存
                    // 注意：因为申请时用了 malloc (或 operator new)，这里要匹配
                    std::free(_cb_pos);
                }
                else {
                    // 普通模式：释放 ControlBlock
                    // 这里 cb_pos 就是 ControlBlock*，强转回去 delete
                    delete static_cast<ControlBlock*>(_cb_pos);
                }
            }
        }
    }

    T* operator->() { return _data_ptr; }
    int use_count() { return _cb ? _cb->_strong_refs.load() : 0; }
};

template<class T, typename... Args>
MySharedPtr<T> Make_MySharedPtr(Args&&... args) {
    // 内存布局结构体
    struct InConBlock {
        ControlBlock control;
        T data;
    };

    // 1. 分配原始内存 (使用 malloc)
    // 【修正】：var 是错的，用 void* 或 auto
    void* rawData = std::malloc(sizeof(InConBlock));
    if (!rawData) throw std::bad_alloc();

    // 2. 强转指针
    InConBlock* iCBPtr = static_cast<InConBlock*>(rawData);

    // 3. 构造 ControlBlock
    new(&iCBPtr->control) ControlBlock();

    // 4. 构造 Data
    // 【修正】：参数包展开必须加 ...
    new(&iCBPtr->data) T(std::forward<Args>(args)...);

    // 5. 返回对象，标记为 continuous = true
    return MySharedPtr<T>(&iCBPtr->data, &iCBPtr->control, rawData, true);
}

// 测试类
class Test {
public:
    int v;
    Test(int val) : v(val) { std::cout << "Test Ctor " << v << "\n"; }
    ~Test() { std::cout << "Test Dtor " << v << "\n"; }
};

int main() {
    std::cout << "--- 1. Make Shared ---\n";
    {
        auto sp = Make_MySharedPtr<Test>(100);
        std::cout << "Use count: " << sp.use_count() << "\n";
    } // 应该输出 Dtor 100

    std::cout << "\n--- 2. Separate New ---\n";
    {
        // 模拟 std::shared_ptr<T>(new T(...))
        MySharedPtr<Test> sp(new Test(200));
        std::cout << "Use count: " << sp.use_count() << "\n";
    } // 应该输出 Dtor 200
}
```

> **为什么用 `struct CombinedBlock`？**
>
> - 如果你直接计算 `sizeof(ControlBlock) + sizeof(T)` 然后 malloc，你必须自己手动计算内存对齐（Alignment）。如果 `T` 需要 16 字节对齐，而 `ControlBlock` 只有 8 字节大小，直接把 `T` 放在 `ControlBlock` 后面会导致 `T` 地址未对齐，引发 Crash 或性能问题。
> - 定义 `CombinedBlock` 结构体，编译器会自动在中间插入 Padding，保证 `data` 是对齐的。
>
> **`std::atomic` 的使用**
>
> - **`fetch_add` / `fetch_sub`**：这是核心。多线程同时修改引用计数时，普通 `int` 会出现数据竞争（Race Condition），导致计数错误（例如两个线程同时读到 1，都减 1，结果变成 0 析构了两次）。
> - **内存序 (`memory_order`)**：
>   - 代码中我用了 `acq_rel` (Acquire-Release)。
>   - 这是为了保证：线程 A 减少引用计数之前的 **所有内存写入操作**，对于线程 B 看到引用计数变为 0 进而去析构对象时，是 **可见的**。
>
> **弱引用的小技巧**
>
> - 构造时 `weak_refs = 1`。这代表“只要强引用计数还 > 0，控制块就不能释放”。
> - 当 `strong` 降为 0 时，我们做一个 `weak_refs--`。如果此时 `weak` 变成了 0，说明既没有强引用（对象已死），也没有弱引用（没人监视控制块了），这时候才能 `free`。
>
> **注意这里实现的 makeshared 用的是 malloc+placementnew，但是标准库用的是 allocator 分配，调用的是全局的:: operator new(size_t)，因此它最后释放的时候用的也是 delete**
>
> 具体看：全局的:: new 和 operator new 这一节

### 内存屏障

### 内存序

https://weakyon.com/2023/07/23/understanding-of-the-cpp-memory-order.html#%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7cache-conherence

这是一个非常硬核的并发编程概念，也是 C++ `std::atomic` 的核心。简单来说，它是 **给 CPU 和编译器立的“交通规则”**。

为了解释它，我们先必须接受一个反直觉的事实：**你的代码，不一定按你写的顺序执行。**

1. 为什么需要内存序？（乱序执行）

为了快，编译器和 CPU 会疯狂优化你的代码。只要结果看起来没变，它们会随意 **重排指令顺序**。

**经典“翻车”场景：** 假设你有两个全局变量 `Data` 和 `Flag`。

- **线程 A（生产者）**：先把数据准备好，然后举起旗子说“好了”。
- **线程 B（消费者）**：一直盯着旗子，看到旗子举起来，就去读数据。

```C++
// 初始状态
int Data = 0;
bool Flag = false;

// 线程 A
void ThreadA() {
    Data = 42;    // 动作 1：写数据
    Flag = true;  // 动作 2：举旗子
}

// 线程 B
void ThreadB() {
    if (Flag == true) {  // 动作 3：看旗子
        assert(Data == 42); // 动作 4：读数据 -> 【这里可能会断言失败！】
    }
}
```

**为什么会挂？** 因为 CPU 可能觉得“动作 1”和“动作 2”没啥关系，为了流水线效率，它可能 **先执行动作 2（Flag = true），后执行动作 1（Data = 42）**。 结果线程 B 看到旗子举起来了，兴冲冲去读数据，读到的却是旧值（或者是乱码）。

**内存序** 就是用来阻止这种乱序的。它告诉 CPU：“在这个操作完成之前，绝对不能把后面的指令提到前面去！”

------

C++ 的三种主要内存序

C++ 提供了 6 种模式，但你只需要懂最常用的这 **3 档**：

第一档：`memory_order_relaxed` (松散序)

- **口诀：** “我就只保原子性，其他的随便乱排。”
- **含义：** 只保证这个操作本身是原子的（不会读到半截数据），但不提供任何顺序保证。
- **适用场景：**
  - 单纯的计数器（如统计网站访问人数）。
  - `shared_ptr` 的引用计数 **增加** 操作（`fetch_add`）。因为增加计数时，如果不涉及对象销毁，谁先加谁后加无所谓，只要没算错就行。

第二档：`memory_order_acquire` / `release` (获取-释放序)

- **口诀：** “一传一接，以此为界。”
- **含义：** 这是一个 **握手协议**。
  - **Release (写)**：也就是线程 A 说：“在我修改这个变量（Flag）**之前** 的所有写操作，都要同步给别人看。”（禁止把前面的写指令移到 Release 后面）。
  - **Acquire (读)**：也就是线程 B 说：“在我读取这个变量（Flag）**之后** 的所有读操作，我都一定要读到最新的。”（禁止把后面的读指令移到 Acquire 前面）。
- **效果：** 线程 A 写了 Data，然后 Release 写 Flag。线程 B Acquire 读 Flag，如果读到了 true，就能 **100% 保证** 读到的 Data 是 42。
- **适用场景：** 互斥锁（Mutex）、信号量、以及 `shared_ptr` 的 **引用计数减为 0 的时候**。

第三档：`memory_order_seq_cst` (顺序一致性)

- **口诀：** “大家排好队，全局看齐。”
- **含义：** 这是 **默认** 的最强模式。它保证所有线程看到的指令执行顺序都是完全一样的，像在单线程里一样自然。
- **代价：** 极慢。它会禁止绝大多数 CPU 缓存优化，通常需要 CPU 插入很重的内存屏障指令（Memory Fence）。
- **适用场景：** 新手默认用这个，或者逻辑极其复杂、一定要全局有序的场景。

回到 `shared_ptr` 的实现

现在回头看我在上一个回答里写的 `make_shared` 引用计数代码，你就能看懂其中的深意了：

```C++
// 增加引用：用 Relaxed
// 为什么？因为增加引用只关心数字+1，此时并不读写 T 对象的数据，
// 也不需要和其他线程同步 T 的状态。乱序也不影响安全性。
_cb->strong_refs.fetch_add(1, std::memory_order_relaxed);

// 减少引用：用 Acq_Rel (Acquire + Release)
// 为什么？这是一个关键节点！
// Release: 保证"我"对对象 T 做的所有修改，在计数器减 1 之前都完成了。
// Acquire: 如果我是减到 0 的那个人，我必须"看到"其他所有人对 T 做的修改，
//          确保在 delete T 之前，大家的手都松开了，数据也是最新的。
if (_cb->strong_refs.fetch_sub(1, std::memory_order_acq_rel) == 1) {
    delete _ptr;
}
```

- **Relaxed**：为了性能，允许乱序，只管自己原子。
- **Acquire/Release**：为了协作，建立由于（A 写 -> B 读）构成的同步点，防止数据读写乱序。
- **Seq_Cst**：为了省脑子，全局绝对有序，但性能最差。

### Weak_ptr 的原理和作用

用法：

```cpp
std::weak_ptr<int> wp;

// ... 在某个地方 wp 被赋值指向了一个 shared_ptr ...

// 正确用法：
if (std::shared_ptr<int> sp = wp.lock()) { // 1. 尝试升级
    // 2. 升级成功：说明对象还活着
    // 此时 sp 持有强引用，对象绝对安全，不会在执行这块代码时突然析构
    std::cout << *sp << std::endl; 
} else {
    // 3. 升级失败：说明对象已经销毁了 (expired)
    std::cout << "对象已死" << std::endl;
}
```



weakPtr 是为了解决 sharedptr 的循环引用问题的

它本质上是持有 sharedptr 的控制块，这个控制块的意义在，可以通过查看控制块的状态（strongRef）来判断它是否还存活

```cpp
#include <iostream>
#include <atomic>
#include <new>
#include <utility> // for std::forward
#include <memory>  // for std::bad_alloc

// ==========================================
// 1. 控制块基类 (抽象层)
// ==========================================
// 负责定义接口：怎么销毁对象(dispose)，怎么释放内存(destroy)
struct ControlBlockBase {
    std::atomic<int> _strong_refs;
    std::atomic<int> _weak_refs;

    ControlBlockBase() : _strong_refs(1), _weak_refs(1) {}
    virtual ~ControlBlockBase() {}

    // 纯虚函数：不同子类实现不同的销毁逻辑
    virtual void dispose() = 0; // 销毁 T 对象
    virtual void destroy() = 0; // 释放 ControlBlock 内存

    // 供 WeakPtr 使用的原子检查并增加强引用 (核心难点)
    bool attempt_inc_strong() {
        int cur = _strong_refs.load(std::memory_order_relaxed);
        while (true) {
            if (cur == 0) return false; // 对象已死，升级失败
            // CAS 操作：只有当 cur 没变时，才将它 +1
            if (_strong_refs.compare_exchange_weak(cur, cur + 1,
                std::memory_order_acquire,
                std::memory_order_relaxed)) {
                return true;
            }
            // CAS 失败会自动更新 cur 为最新值，继续循环
        }
    }
};

// ==========================================
// 2. 两种具体的控制块实现
// ==========================================

// 情况 A: 对应 MySharedPtr(new T)
// 内存分离：CB 和 T 是分开 new 的
template<typename T>
struct ControlBlockPtr : public ControlBlockBase {
    T* _ptr;
    ControlBlockPtr(T* p) : _ptr(p) {}

    virtual void dispose() override {
        delete _ptr; // 直接 delete 指针
    }
    virtual void destroy() override {
        delete this; // 销毁控制块自己
    }
};

// 情况 B: 对应 Make_MySharedPtr
// 内存连续：CB 后面紧跟着 T
template<typename T>
struct ControlBlockInplace : public ControlBlockBase {
    // 这里的 storage 只是占位，不自动构造
    typename std::aligned_storage<sizeof(T), alignof(T)>::type _storage;

    template<typename... Args>
    ControlBlockInplace(Args&&... args) {
        // 在 _storage 上原地构造 T
        new (&_storage) T(std::forward<Args>(args)...);
    }

    T* get_ptr() { return reinterpret_cast<T*>(&_storage); }

    virtual void dispose() override {
        // 手动调用析构函数
        get_ptr()->~T();
    }
    virtual void destroy() override {
        // 释放整个 ControlBlockInplace 内存 (包含 T 的尸体)
        delete this;
    }
};

// 前置声明
template<typename T> class MyWeakPtr;

// ==========================================
// 3. MySharedPtr 实现
// ==========================================
template<typename T>
class MySharedPtr {
    // 允许 MyWeakPtr 访问私有成员 (为了 lock() 函数)
    friend class MyWeakPtr<T>;

private:
    T* _data_ptr = nullptr;
    ControlBlockBase* _cb = nullptr;



public:
    MySharedPtr() = default;
    // 私有构造：供 lock() 和 make_shared 使用
    MySharedPtr(T* data, ControlBlockBase* cb) : _data_ptr(data), _cb(cb) {}
    // 构造函数：接管裸指针
    explicit MySharedPtr(T* data) : _data_ptr(data) {
        if (data) {
            _cb = new ControlBlockPtr<T>(data);
        }
    }

    // 拷贝构造
    MySharedPtr(const MySharedPtr& other) {
        _data_ptr = other._data_ptr;
        _cb = other._cb;
        if (_cb) _cb->_strong_refs.fetch_add(1, std::memory_order_relaxed);
    }

    // 析构函数 (关键生命周期逻辑)
    ~MySharedPtr() {
        if (!_cb) return;

        // 1. 强引用减 1
        if (_cb->_strong_refs.fetch_sub(1, std::memory_order_acq_rel) == 1) {
            // 2. 如果强引用归零 -> 销毁对象 (调用 dispose)
            _cb->dispose();

            // 3. 强引用归零意味着我们要放弃对 CB 的一个弱锁定
            //    检查弱引用是否也归零 -> 释放内存 (调用 destroy)
            if (_cb->_weak_refs.fetch_sub(1, std::memory_order_acq_rel) == 1) {
                _cb->destroy();
            }
        }
    }
    explicit operator bool() const {
        return _data_ptr != nullptr; // 或者检查 _cb
    }
    T* operator->() { return _data_ptr; }
    T& operator*() { return *_data_ptr; }
    int use_count() { return _cb ? _cb->_strong_refs.load() : 0; }
};

// ==========================================
// 4. MyWeakPtr 实现
// ==========================================
template<typename T>
class MyWeakPtr {
private:
    T* _data_ptr = nullptr;
    ControlBlockBase* _cb = nullptr;

public:
    MyWeakPtr() = default;

    // 构造：从 SharedPtr 创建 WeakPtr
    MyWeakPtr(const MySharedPtr<T>& sp) {
        _data_ptr = sp._data_ptr;
        _cb = sp._cb;
        if (_cb) {
            // 只增加弱引用！
            _cb->_weak_refs.fetch_add(1, std::memory_order_relaxed);
        }
    }

    // 析构
    ~MyWeakPtr() {
        if (!_cb) return;
        // 弱引用减 1
        // 如果变成 0，说明没有任何 SharedPtr (对象早没了) 也没任何 WeakPtr
        // 这时才能释放 ControlBlock 的物理内存
        if (_cb->_weak_refs.fetch_sub(1, std::memory_order_acq_rel) == 1) {
            _cb->destroy();
        }
    }

    // 【核心方法】：升级为 SharedPtr
    MySharedPtr<T> lock() const {
        if (!_cb) return MySharedPtr<T>();

        // 尝试原子地增加强引用
        // 必须使用 CAS 循环，防止多线程竞争时对象刚好被析构
        if (_cb->attempt_inc_strong()) {
            return MySharedPtr<T>(_data_ptr, _cb);
        }

        return MySharedPtr<T>(); // 升级失败，返回空
    }

    bool expired() const {
        return !_cb || _cb->_strong_refs.load() == 0;
    }
};

// ==========================================
// 5. Make_MySharedPtr 实现
// ==========================================
template<typename T, typename... Args>
MySharedPtr<T> Make_MySharedPtr(Args&&... args) {
    // 1. 分配并构造 ControlBlockInplace (包含 T)
    // 这里直接 new 子类，不仅分配了 CB，也分配了 T 的内存
    auto* cb = new ControlBlockInplace<T>(std::forward<Args>(args)...);

    // 2. 返回 SharedPtr
    return MySharedPtr<T>(cb->get_ptr(), cb);
}

// ==========================================
// 测试代码
// ==========================================
class Test {
public:
    int id;
    Test(int i) : id(i) { std::cout << "  Ctor " << id << "\n"; }
    ~Test() { std::cout << "  Dtor " << id << "\n"; }
};

int main() {
    // 1. 测试 MakeShared 和 WeakPtr
    std::cout << "--- Test WeakPtr ---\n";
    MyWeakPtr<Test> wp;
    {
        auto sp = Make_MySharedPtr<Test>(1);
        wp = sp; // 产生弱引用
        std::cout << "  Use count: " << sp.use_count() << "\n";

        // 尝试 lock
        if (auto sp2 = wp.lock()) {
            std::cout << "  Lock success! Value: " << sp2->id << "\n";
        }
    } // sp 析构 -> Strong=0 -> Dispose(~Test) -> Weak=1 (因为 wp 还在) -> Memory NOT freed

    std::cout << "--- Sp out of scope ---\n";

    // 此时 wp 还在，ControlBlock 内存未释放，但 Test 对象已析构
    if (auto sp3 = wp.lock()) {
        std::cout << "  Lock success?\n";
    }
    else {
        std::cout << "  Lock failed (Object expired)\n";
    }

    return 0; // wp 析构 -> Weak=0 -> Destroy(free memory)
}
```



### makeShared 缺点

1. 内存延迟释放

如果你使用 `weak_ptr` 配合 `make_shared`： 即使 `shared_ptr` 也就是强引用都死光了，对象析构了，**只要还有一个 `weak_ptr` 活着，那块 `ControlBlock` 连同 `Object` 占用的整块内存（如果是 make_shared 连在一起的）都不会释放**。

`weak_ptr` 会锁住物理内存，直到它自己也析构。所以如果对象特别大（比如 100MB 的纹理），且 `weak_ptr` 生命周期很长，要慎用 `make_shared`，最好改用 `new` 分离式内存。

2. 极端的大内存分配失败 (Memory Fragmentation)

虽然少见，但在内存碎片严重的机器上（比如旧的主机平台）可能发生。

- **问题：** `make_shared` 需要分配一块 **连续的、巨大的** 内存（对象大小 + 控制块大小）。
- **对比：** 传统 `new` 是分开两次分配较小的内存。
- **场景：** 有时候内存总量够，但就是找不到这么大一块连续的区域，导致分配失败。而分开分配两次小内存可能就能成功。

3. 它不支持自定义删除器

标准库的默认构造方法支持传入一个删除 lambda，但是 make_shared 不支持，因为 make_shared 的内部控制块是用 malloc 统一分配的，回收的时候也要用 free，就限制死了



### 不使用 weakptr 的情况下解决 shared_ptr 的循环引用



## 多态

### 动态多态的原理

### 虚函数表和虚函数的存储位置

### 多继承下类的内存结构

### 菱形继承下的 类的内存结构

### 虚基类的实现原理和内存结构

### 虚基类+虚函数的内存结构

### dynamic_cast 的实现原理



## 元编程（泛型）

### 泛型的实现原理

### template 为什么定义和实现都要在头文件

### 什么是类型擦除

### 类型萃取 + 迭代器实现

### 什么是偏特化

### 右值引用和万能引用

### std: move 和 std:: forward 的实现以及原理

### 模板函数可以是虚函数吗





## 其他

### inline 的原理和作用

### volatile 和 atomic

### constexpr 和 Const

### 顶层底层 Const

### lambda 表达式的原理

### 函数对象是什么，如何实现的函数对象的效果以及 std: functional

### Name Mangling





## 现代 C++

### 有什么 C++17/20 的新特性吗

# Unity

## Unity 基础

### 协程的原理

### 协程的 GC

### Unity 生命周期函数

### Unity 的相机渲染以及多相机渲染（如何排序，如何筛选）

### Unity 相机的剔除

### 如何判断一个对象是否在屏幕内

### 如何判断一个点是否在三角形内部

### 如何判断射线和包围盒相交

### 如何判断两个包围盒相交

### 如何判断两个三角形相交

### FixedUpdate 的原理

### Unity 的 OverDrall 问题

### Unity 如何引入 C++代码

### 欧拉角和万向锁

### GPUInstacing

### AB 包和资源管理，Unity 是如何找到资源的



## UGUI

### UGUI 绘制流程，包括如何材质和布局

### UGUI 布局更新逻辑，如何递归的获取子节点以及如何反递归的设置各层的大小

### Pivot，Anchor 和 RectTransform

### 屏幕坐标系和 UI 局部坐标系的异同

### Canvas 的分类，每一类都是如何对应的

### UGUI 的合批，断批的条件

### UGUI 和 Rebuild 和 ReBatch 的异同



## Built-in 和 URP

### Built-in 的动态静态合批

### SRP 的优化重点和 Built-in 的区别

### **SRP Batcher**





## 设计模式

### MVC，MVVM 结合项目

### ECS 结合实习

### 单例模式





## 寻路

### Unity 的 NavMesh 的原理

### AStar 的实现

### DFS，迪杰斯特拉



## AI

### 状态机和分层状态机

### 行为树



## 动画

### 混合树

### Avatar 和遮罩

### Animator 和 Animation 的区别



## 其他

### 贝母 GC

# 图形学

## 渲染

### 渲染流程

### EarlyZ

### 为什么 AlphaTest 或者说是 Discard 会打断 EarlyZ

### 前向渲染和延迟渲染



### 不透明物体的渲染顺序应该是怎样的

### 透明渲染

### 顺序无关的透明效果



## 阴影

### 硬阴影

### ShadowMap，以及 ShadowMap 的 Bias 如何解决毛刺，以及 MipMap

### CSM



## 反走样和摩尔纹

### MipMap

### MSAA，TSAA，SSAA

### 各向异性



## 高级图形学

### AO 和 SSAO

### PBR 的 BRDF 公式

### PBR 的基本原理

### IBL 的实现是如何的

### 如何实现 SkyBox



## 其他

### 各种剔除的方法（区分 CPU 时候的剔除和 GPU 时候的剔除），视锥剔除和裁剪

### AABB 和 OBB

### 八叉树，KDTree，BVH

### Gamma 矫正，线性空间





### LOD

### 欧拉角和欧拉角

### 凹凸贴图，法线贴图等



## DX12

### DX12 的创建渲染流程



# C#

## 协变





# Lua

## Lua 基础

### Lua 的 String 实现和问题

### Lua 的类型

### Lua 实现面向对象



## LuaGC

### 渐进式 GC 的状态机流程

### 三色标记法和渐进式 GC

### 渐进式 GC 的各个阶段的作用

### 写入屏障

### 分代 GC



## XLua

### XLua 如何和 C#交互

### XLua 下 C#的 Struct 和 Class 的区别（值类型和引用类型在传递的区别）

### XLua 的虚拟机在哪个分区？



# OS

## 进程和线程

## 分页和分段

## 进程间通信

## SysCall

### 原子，信号量

### 生产者消费者问题

### 虚拟内存的原理和实现方法

### 内存轮转，FIFO，LFO 等



# 场景

## 战争迷雾优化顶点树

